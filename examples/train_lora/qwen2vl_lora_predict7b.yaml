### model
model_name_or_path: /share/hezijian/LLaMA-Factory/models/qwen2_vl
#adapter_name_or_path: saves/qwen2_vl-7b/dpo/train_v0
adapter_name_or_path: saves/qwen2_vl-7b/split/train_split_v0
flash_attn: fa2
### method
stage: sft
do_predict: true
finetuning_type: lora

### dataset
eval_dataset: emma_val_split_v0 
template: qwen2_vl
cutoff_len: 4096
overwrite_cache: true
preprocessing_num_workers: 16
#image_resolution: 540000 # pixel limit of max(hidth,height) From _preprocess_image of:  /mnt/ve_share/hezijian/LLaMA-Factory/src/llamafactory/data/mm_plugin.py
image_max_pixels: 90000 #TODO replace image_resolution
### output
output_dir: saves/qwen2_vl-7b/predict/predict_split_v0
#output_dir: saves/qwen2_vl-7b/single/predict_single_v0_clean
overwrite_output_dir: true

### eval
per_device_eval_batch_size: 20 #16
predict_with_generate: true
ddp_timeout: 180000000
temperature: 0.01
# infer_backend: vllm
# vllm_enforce_eager: true

### data
# new_special_tokens: "<|traj_start|>,<|traj_end|>" 
# resize_vocab: True
#skip_special_tokens: False #Output for debug