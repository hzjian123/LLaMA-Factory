### model
model_name_or_path: /share/hezijian/LLaMA-Factory/models/qwen2_vl #Qwen/Qwen2-VL-7B-Instruct
flash_attn: fa2
#adapter_name_or_path: saves/qwen2_vl-7b/single/train_single_v0_structured
### method
stage: sft
do_train: true
do_eval: true
finetuning_type: lora
lora_target: all
### dataset
dataset: emma_train_split_v0
template: qwen2_vl
cutoff_len: 4096
#max_samples: 1000
overwrite_cache: true
preprocessing_num_workers: 28
#image_resolution: 540000 #1200*450
image_max_pixels: 90000 #TODO replace image_resolution
#tokenized_path: saves/nus_emma_fast #For  faster loading

### output
output_dir: saves/qwen2_vl-7b/split/train_split_v0 #saves/qwen2_vl-7b/ablations/train_ablationV6_e30
logging_steps: 5
save_steps: 50000 #5000
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 16 #8
gradient_accumulation_steps: 2
learning_rate: 2.0e-4 #2e-4
num_train_epochs: 10
#lora_dropout: 0
lr_scheduler_type: cosine
warmup_ratio: 0.1 #0.1
bf16: true
ddp_timeout: 180000000
deepspeed: examples/deepspeed/ds_z3_config.json
### eval
#val_size: 300
eval_dataset: emma_val_single_v0_mini_share # video: mllm_video_demo
per_device_eval_batch_size: 8
eval_strategy: steps
eval_steps: 100000
#### data
# new_special_tokens: "<|traj_start|>,<|traj_end|>" 
# resize_vocab: True
#skip_special_tokens: False #Output for debug
# streaming: true
# max_steps: 100000